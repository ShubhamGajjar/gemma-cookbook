A wish list of cookbooks showcasing:

* Inference

* Fine-tuning
  * Fine-tuning Gemma for function calling
  * Fine-tuning Gemma and/or CodeGemma for multi-turn, agentic workloads.

* Continued Pretraining
  * Continue to pretrain Gemma on TPU
     
* Responsible AI
  * Use [LLM Comparator](https://github.com/pair-code/llm-comparator) to compare Gemma with another LLM (i.e., Llama)
